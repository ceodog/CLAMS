{"cells":[{"cell_type":"code","execution_count":1,"id":"TDB3UfhXbVhA","metadata":{"id":"TDB3UfhXbVhA","executionInfo":{"status":"ok","timestamp":1719053972836,"user_tz":240,"elapsed":7,"user":{"displayName":"Xiaofeng Tan","userId":"13213533501740266205"}}},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":2,"id":"pj7RzaLZbh61","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26913,"status":"ok","timestamp":1719053999743,"user":{"displayName":"Xiaofeng Tan","userId":"13213533501740266205"},"user_tz":240},"id":"pj7RzaLZbh61","outputId":"34b3fbd1-a8d1-45be-9298-d7f26c65ad17"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running on CoLab, mounting google drive...\n","Mounted at /content/drive\n"]}],"source":["import os\n","import sys\n","\n","detanet_dir = \"/content/drive/MyDrive/Colab Notebooks/DetaNet/code\"\n","\n","if 'google.colab' in str(get_ipython()):\n","  from google.colab import drive\n","  import sys\n","\n","  print('Running on CoLab, mounting google drive...')\n","  drive.mount('/content/drive')\n","\n","  base_dir = \"/content/drive/MyDrive/Colab Notebooks/CLAMS\"\n","else:\n","  base_dir = os.getcwd()\n","  print('Not running on CoLab')\n","\n","src_dir = os.path.join(base_dir, \"src\")\n","\n","sys.path.append(base_dir)\n","sys.path.append(src_dir)\n","sys.path.append(detanet_dir)"]},{"cell_type":"code","execution_count":3,"id":"4ee4de42-c002-4d9e-9ace-66110bd27a38","metadata":{"id":"4ee4de42-c002-4d9e-9ace-66110bd27a38","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719054116496,"user_tz":240,"elapsed":116758,"user":{"displayName":"Xiaofeng Tan","userId":"13213533501740266205"}},"outputId":"24cc1912-2377-473d-9946-53a539fb2c6d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting dataset\n","  Downloading dataset-1.6.2-py2.py3-none-any.whl (18 kB)\n","Collecting sqlalchemy<2.0.0,>=1.3.2 (from dataset)\n","  Downloading SQLAlchemy-1.4.52-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting alembic>=0.6.2 (from dataset)\n","  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting banal>=1.0.1 (from dataset)\n","  Downloading banal-1.0.6-py2.py3-none-any.whl (6.1 kB)\n","Collecting Mako (from alembic>=0.6.2->dataset)\n","  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=0.6.2->dataset) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<2.0.0,>=1.3.2->dataset) (3.0.3)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=0.6.2->dataset) (2.1.5)\n","Installing collected packages: banal, sqlalchemy, Mako, alembic, dataset\n","  Attempting uninstall: sqlalchemy\n","    Found existing installation: SQLAlchemy 2.0.30\n","    Uninstalling SQLAlchemy-2.0.30:\n","      Successfully uninstalled SQLAlchemy-2.0.30\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.52 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed Mako-1.3.5 alembic-1.13.1 banal-1.0.6 dataset-1.6.2 sqlalchemy-1.4.52\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n","Collecting rdkit\n","  Downloading rdkit-2023.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.25.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n","Installing collected packages: rdkit\n","Successfully installed rdkit-2023.9.6\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n","Collecting accelerate\n","  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.4)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.15.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.6.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n","Successfully installed accelerate-0.31.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n","Collecting e3nn\n","  Downloading e3nn-0.5.1-py3-none-any.whl (118 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from e3nn) (1.12.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from e3nn) (1.11.4)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from e3nn) (2.3.0+cu121)\n","Collecting opt-einsum-fx>=0.1.4 (from e3nn)\n","  Downloading opt_einsum_fx-0.1.4-py3-none-any.whl (13 kB)\n","Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from opt-einsum-fx>=0.1.4->e3nn) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from opt-einsum-fx>=0.1.4->e3nn) (24.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->e3nn) (3.15.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->e3nn) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->e3nn) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->e3nn) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->e3nn) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->e3nn) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->e3nn) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->e3nn) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->e3nn) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->e3nn) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->e3nn) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->e3nn) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->e3nn) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->e3nn) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->e3nn) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->e3nn) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->e3nn) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->e3nn) (12.5.40)\n","Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->e3nn) (1.25.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->e3nn) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->e3nn) (2.1.5)\n","Installing collected packages: opt-einsum-fx, e3nn\n","Successfully installed e3nn-0.5.1 opt-einsum-fx-0.1.4\n","Collecting torch_geometric\n","  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.25.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2023.6.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.9.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.6.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.5.0)\n","Installing collected packages: torch_geometric\n","Successfully installed torch_geometric-2.5.3\n","Looking in links: https://data.pyg.org/whl/torch-2.2.1+cu121.html\n","Collecting torch-cluster==1.6.3\n","  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu121/torch_cluster-1.6.3%2Bpt22cu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-cluster==1.6.3) (1.11.4)\n","Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-cluster==1.6.3) (1.25.2)\n","Installing collected packages: torch-cluster\n","Successfully installed torch-cluster-1.6.3+pt22cu121\n","Looking in links: https://data.pyg.org/whl/torch-2.2.1+cu121.html\n","Collecting torch-scatter==2.1.2\n","  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu121/torch_scatter-2.1.2%2Bpt22cu121-cp310-cp310-linux_x86_64.whl (10.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-scatter\n","Successfully installed torch-scatter-2.1.2+pt22cu121\n"]}],"source":["!pip install dataset\n","!pip install transformers\n","!pip install rdkit\n","!pip install tqdm\n","!pip install accelerate -U\n","!pip install e3nn\n","!pip install torch_geometric\n","!pip install torch-cluster==1.6.3 -f https://data.pyg.org/whl/torch-2.2.1+cu121.html\n","!pip install torch-scatter==2.1.2 -f https://data.pyg.org/whl/torch-2.2.1+cu121.html"]},{"cell_type":"code","execution_count":4,"id":"28526e9b-ae59-439a-ab4d-093ef073a671","metadata":{"id":"28526e9b-ae59-439a-ab4d-093ef073a671","executionInfo":{"status":"ok","timestamp":1719054116497,"user_tz":240,"elapsed":7,"user":{"displayName":"Xiaofeng Tan","userId":"13213533501740266205"}}},"outputs":[],"source":["import logging\n","import sys\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Create logger\n","logger = logging.getLogger()\n","logger.setLevel(logging.INFO)\n","\n","# Create STDERR handler\n","handler = logging.StreamHandler(sys.stdout)\n","\n","# Create formatter and add it to the handler\n","formatter = logging.Formatter('%(asctime)-15s %(name)s - %(levelname)s - %(message)s')\n","handler.setFormatter(formatter)\n","\n","# Set STDERR handler as the only handler\n","logger.handlers = [handler]"]},{"cell_type":"markdown","id":"d260ab1c-3869-45f3-8c47-797dfb5000e5","metadata":{"id":"d260ab1c-3869-45f3-8c47-797dfb5000e5"},"source":["# Read Data"]},{"cell_type":"code","execution_count":5,"id":"1457b93e-5002-4010-84ed-b0e562c3adf3","metadata":{"id":"1457b93e-5002-4010-84ed-b0e562c3adf3","executionInfo":{"status":"ok","timestamp":1719054119861,"user_tz":240,"elapsed":3369,"user":{"displayName":"Xiaofeng Tan","userId":"13213533501740266205"}}},"outputs":[],"source":["import json\n","\n","model_config = {\n","    'run4': {\n","        'vit': {\n","            'num_classes': 37,\n","            'hidden_size': 288,\n","            'num_hidden_layers': 9,\n","            'num_attention_heads': 9,\n","            'intermediate_size': 576,\n","            'num_channels': 1,\n","            'image_size': (66, 66),\n","            'patch_size': (6, 6),\n","            'hidden_dropout_prob': 0.1,\n","            'attention_probs_dropout_prob': 0.1,\n","            'batch_size': 300,\n","            'model_dir': os.path.join(base_dir, \"models\", \"vit_models\", 'run4')\n","        },\n","        'vit_training': {\n","            'num_epochs': 100,\n","            'lr': 1e-3,\n","            'step_size': 1,\n","            'gamma': 0.975,\n","            'early_stopping_epochs': 5,\n","        },\n","        'ic_training': {\n","            'batch_size': 300,\n","            'model_dir': os.path.join(base_dir, \"models\", \"ic_models\", 'run4'),\n","            'num_train_epochs': 120,\n","            'save_total_limit': 3,\n","            'max_length': 30,\n","            'num_beams': 5,\n","            'early_stopping_patience': 5,\n","            'canonicalize': True\n","        }\n","    },\n","    'run7': {\n","        'vit': {\n","            'num_classes': 18,\n","            'hidden_size': 288,\n","            'num_hidden_layers': 9,\n","            'num_attention_heads': 9,\n","            'intermediate_size': 576,\n","            'num_channels': 1,\n","            'image_size': (66, 66),\n","            'patch_size': (6, 6),\n","            'hidden_dropout_prob': 0.1,\n","            'attention_probs_dropout_prob': 0.1,\n","            'batch_size': 300,\n","            'model_dir': os.path.join(base_dir, \"models\", \"vit_models\", 'run7')\n","        },\n","        'vit_training': {\n","            'num_epochs': 100,\n","            'lr': 1e-3,\n","            'step_size': 1,\n","            'gamma': 0.975,\n","            'early_stopping_epochs': 5,\n","        },\n","        'ic_training': {\n","            'batch_size': 300,\n","            'model_dir': os.path.join(base_dir, \"models\", \"ic_models\", 'run7'),\n","            'num_train_epochs': 120,\n","            'save_total_limit': 3,\n","            'max_length': 30,\n","            'num_beams': 5,\n","            'early_stopping_patience': 5,\n","            'canonicalize': False\n","        },\n","    },\n","    'run8': {\n","        'vit': {\n","            'num_classes': 18,\n","            'hidden_size': 288,\n","            'num_hidden_layers': 9,\n","            'num_attention_heads': 9,\n","            'intermediate_size': 576,\n","            'num_channels': 1,\n","            'image_size': (60, 60),\n","            'patch_size': (6, 6),\n","            'hidden_dropout_prob': 0.1,\n","            'attention_probs_dropout_prob': 0.1,\n","            'batch_size': 300,\n","            'model_dir': os.path.join(base_dir, \"models\", \"vit_models\", 'run8')\n","        },\n","        'vit_training': {\n","            'num_epochs': 100,\n","            'lr': 1e-3,\n","            'step_size': 1,\n","            'gamma': 0.975,\n","            'early_stopping_epochs': 5,\n","        },\n","        'ic_training': {\n","            'batch_size': 300,\n","            'model_dir': os.path.join(base_dir, \"models\", \"ic_models\", 'run8'),\n","            'num_train_epochs': 120,\n","            'save_total_limit': 3,\n","            'max_length': 30,\n","            'num_beams': 5,\n","            'early_stopping_patience': 5,\n","            'canonicalize': False\n","        },\n","    },\n","}\n","\n","with open(os.path.join(base_dir, \"configs/model_config.json\"), \"w\") as f_hd:\n","    json.dump(model_config, f_hd)"]},{"cell_type":"code","execution_count":6,"id":"2a978f9e-0ad2-4b14-a583-c7cbf357ad80","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":353011,"status":"ok","timestamp":1719054472868,"user":{"displayName":"Xiaofeng Tan","userId":"13213533501740266205"},"user_tz":240},"id":"2a978f9e-0ad2-4b14-a583-c7cbf357ad80","outputId":"1131e12b-940d-4121-ab41-e6f2b2456833"},"outputs":[{"output_type":"stream","name":"stdout","text":["2024-06-22 11:02:26,279 rdkit - INFO - Enabling RDKit 2023.09.6 jupyter extensions\n","2024-06-22 11:02:29,407 numexpr.utils - INFO - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n","2024-06-22 11:02:29,409 numexpr.utils - INFO - NumExpr defaulting to 8 threads.\n","2024-06-22 11:02:29,713 root - INFO - Loading ir feature data from /content/drive/MyDrive/Colab Notebooks/CLAMS/data/ir_features.pth...\n","2024-06-22 11:05:00,863 root - INFO - Loading ir label data from /content/drive/MyDrive/Colab Notebooks/CLAMS/data/ir_labels.pth...\n","2024-06-22 11:05:18,999 root - INFO - Loading uv feature data from /content/drive/MyDrive/Colab Notebooks/CLAMS/data/uv_features.pth...\n","2024-06-22 11:05:36,051 root - INFO - Loading uv label data from /content/drive/MyDrive/Colab Notebooks/CLAMS/data/uv_labels.pth...\n","2024-06-22 11:05:45,508 root - INFO - Loading nmr feature data from /content/drive/MyDrive/Colab Notebooks/CLAMS/data/nmr_features.pth...\n","2024-06-22 11:06:14,308 root - INFO - Loading nmr label data from /content/drive/MyDrive/Colab Notebooks/CLAMS/data/nmr_labels.pth...\n","2024-06-22 11:06:26,750 root - INFO - Consolidating data...\n","2024-06-22 11:06:30,865 root - INFO - Removing 2307 bad records from data!!!\n","2024-06-22 11:06:58,049 root - INFO - Further removing 45 bad records from data: [23, 169, 176, 303, 464, 745, 791, 3663, 8195, 8416, 13839, 20761, 20770, 20774, 20784, 20785, 20985, 22712, 22716, 22742, 22748, 22758, 22776, 31672, 122842, 122845, 122852, 122855, 122857, 124370, 124378, 124455, 124521, 125697, 125916, 126030, 126087, 127048, 127051, 127066, 127090, 127092, 127093, 127097, 127123]\n"]}],"source":["from ir_dataset import IrDataset\n","from ir_smarts import SMARTS\n","\n","run = 'run8'\n","config = model_config[run]\n","\n","ds = IrDataset(data_list=None, data_path=os.path.join(base_dir, \"data\"), \\\n","               use_transmittance=False, ir_only=True, \\\n","               canonicalize=config['ic_training']['canonicalize'], \\\n","               smarts=SMARTS,\n","               further_remove=[23, 169, 176, 303, 464, 745, 791, 3663, 8195, \\\n","                               8416, 13839, 20761, 20770, 20774, 20784, 20785, \\\n","                               20985, 22712, 22716, 22742, 22748, 22758, 22776, \\\n","                               31672, 122842, 122845, 122852, 122855, 122857, \\\n","                               124370, 124378, 124455, 124521, 125697, 125916, \\\n","                               126030, 126087, 127048, 127051, 127066, 127090, \\\n","                               127092, 127093, 127097, 127123])\n","ds.load()"]},{"cell_type":"code","execution_count":7,"id":"c104f3d4-e99c-4374-9f26-ef1a165c2c10","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1719054472868,"user":{"displayName":"Xiaofeng Tan","userId":"13213533501740266205"},"user_tz":240},"id":"c104f3d4-e99c-4374-9f26-ef1a165c2c10","outputId":"570f8d75-a2b3-4d6a-8972-1acc51dd1b51"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["127465"]},"metadata":{},"execution_count":7}],"source":["len(ds)"]},{"cell_type":"markdown","id":"2442acf2-b4f7-43c4-aebe-8675606de90f","metadata":{"id":"2442acf2-b4f7-43c4-aebe-8675606de90f"},"source":["# Prepare Data for Training"]},{"cell_type":"code","execution_count":10,"id":"5ac29101-fc12-46e9-ad88-b91bd75d44d9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":356,"status":"ok","timestamp":1719054486520,"user":{"displayName":"Xiaofeng Tan","userId":"13213533501740266205"},"user_tz":240},"id":"5ac29101-fc12-46e9-ad88-b91bd75d44d9","outputId":"fcde8aa3-32fd-4b8e-d8b8-8b929b56d97b"},"outputs":[{"output_type":"stream","name":"stdout","text":["2024-06-22 11:08:06,062 root - INFO - Training set size: 101972\n","2024-06-22 11:08:06,063 root - INFO - Validation set size: 12746\n","2024-06-22 11:08:06,064 root - INFO - Testing set size: 12747\n"]}],"source":["import torch\n","from torch.utils.data import DataLoader, Dataset, random_split\n","\n","batch_size = config['vit']['batch_size']\n","\n","# Define the sizes of training, validation, and test sets\n","train_size = int(0.8 * len(ds))  # 80% of the data for training\n","val_size = int(0.1 * len(ds))    # 10% of the data for validation\n","test_size = len(ds) - train_size - val_size  # Remaining for testing\n","\n","# Use random_split to split the dataset\n","torch.manual_seed(622)\n","train_dataset, val_dataset, test_dataset = random_split(ds, [train_size, val_size, test_size])\n","\n","# You can optionally print the sizes of the splits\n","logging.info(f\"Training set size: {len(train_dataset)}\")\n","logging.info(f\"Validation set size: {len(val_dataset)}\")\n","logging.info(f\"Testing set size: {len(test_dataset)}\")\n","\n","num_workers = 4\n","prefetch_factor = 2\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, \\\n","                          num_workers=num_workers, prefetch_factor=prefetch_factor)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, \\\n","                        num_workers=num_workers, prefetch_factor=prefetch_factor)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"]},{"cell_type":"markdown","source":["# Inspect the Vit Model Architecture"],"metadata":{"id":"pgcLrxXanNLF"},"id":"pgcLrxXanNLF"},{"cell_type":"code","source":["from encoder import Encoder\n","import torch\n","\n","config = model_config[run]\n","vit_model = Encoder(config['vit'], torch.device(\"cpu\"))\n","vit_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lz6FJ2iinKCk","executionInfo":{"status":"ok","timestamp":1719054498040,"user_tz":240,"elapsed":2192,"user":{"displayName":"Xiaofeng Tan","userId":"13213533501740266205"}},"outputId":"bf2b92ef-a1c3-43c8-e3b7-8a48f72158c2"},"id":"lz6FJ2iinKCk","execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Encoder(\n","  (vit): ViTModel(\n","    (embeddings): ViTEmbeddings(\n","      (patch_embeddings): ViTPatchEmbeddings(\n","        (projection): Conv2d(1, 288, kernel_size=(6, 6), stride=(6, 6))\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): ViTEncoder(\n","      (layer): ModuleList(\n","        (0-8): 9 x ViTLayer(\n","          (attention): ViTSdpaAttention(\n","            (attention): ViTSdpaSelfAttention(\n","              (query): Linear(in_features=288, out_features=288, bias=True)\n","              (key): Linear(in_features=288, out_features=288, bias=True)\n","              (value): Linear(in_features=288, out_features=288, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=288, out_features=288, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=288, out_features=576, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=576, out_features=288, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((288,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((288,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","    (layernorm): LayerNorm((288,), eps=1e-12, elementwise_affine=True)\n","    (pooler): ViTPooler(\n","      (dense): Linear(in_features=288, out_features=288, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (classifier): Linear(in_features=288, out_features=18, bias=True)\n",")"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","id":"684cc084-9c4c-40ea-b97e-cb73c17fbfe2","metadata":{"id":"684cc084-9c4c-40ea-b97e-cb73c17fbfe2"},"source":["# Train the Vit + MLP for Classification of Functional Groups"]},{"cell_type":"code","execution_count":12,"id":"5ba74f37-9a71-4630-8614-283e28248d32","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":390,"status":"ok","timestamp":1719054502839,"user":{"displayName":"Xiaofeng Tan","userId":"13213533501740266205"},"user_tz":240},"id":"5ba74f37-9a71-4630-8614-283e28248d32","outputId":"6e40c269-cb02-478c-c883-1b097bc9636d"},"outputs":[{"output_type":"stream","name":"stdout","text":["2024-06-22 11:08:22,268 root - INFO - Device: cuda\n"]}],"source":["import torch\n","\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","else:\n","    device = torch.device(\"cpu\")\n","\n","logging.info(\"Device: %s\", device)"]},{"cell_type":"code","execution_count":null,"id":"9a17f631-4d66-4d18-b92e-66054772bc30","metadata":{"id":"9a17f631-4d66-4d18-b92e-66054772bc30","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715538923609,"user_tz":240,"elapsed":5379470,"user":{"displayName":"Xiaofeng Tan","userId":"13213533501740266205"}},"outputId":"8b07ea9c-63c5-4219-a2c5-ca608df14394"},"outputs":[{"output_type":"stream","name":"stdout","text":["2024-05-12 17:05:47,690 root - ERROR - Error loading model weights: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/AISpec/models/vit_models/run8/model_weights.pth'\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:06<00:00,  2.70it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100, Train Loss: 0.2899025086070704\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 17:07:59,633 root - INFO - Epoch 1/100, Validation Loss: 0.28625208260723023\n","2024-05-12 17:07:59,635 root - INFO - Saving model weights...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.66it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100, Train Loss: 0.26189831262506247\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 17:10:13,830 root - INFO - Epoch 2/100, Validation Loss: 0.23782741613163125\n","2024-05-12 17:10:13,833 root - INFO - Saving model weights...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:09<00:00,  2.63it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/100, Train Loss: 0.20412713914300945\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 17:12:29,163 root - INFO - Epoch 3/100, Validation Loss: 0.18881928223776787\n","2024-05-12 17:12:29,165 root - INFO - Saving model weights...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.66it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/100, Train Loss: 0.1555533471564229\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 17:14:42,980 root - INFO - Epoch 4/100, Validation Loss: 0.1496768934057232\n","2024-05-12 17:14:42,982 root - INFO - Saving model weights...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.66it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/100, Train Loss: 0.13444840106197212\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 17:16:56,728 root - INFO - Epoch 5/100, Validation Loss: 0.16081195618978025\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.65it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/100, Train Loss: 0.12491377347218562\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 17:19:11,086 root - INFO - Epoch 6/100, Validation Loss: 0.19623891443642866\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.66it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 7/100, Train Loss: 0.11794425587557444\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 17:21:25,078 root - INFO - Epoch 7/100, Validation Loss: 0.1205512910389487\n","2024-05-12 17:21:25,080 root - INFO - Saving model weights...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:09<00:00,  2.63it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 8/100, Train Loss: 0.10925794707710683\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 17:23:40,610 root - INFO - Epoch 8/100, Validation Loss: 0.1078373360293546\n","2024-05-12 17:23:40,612 root - INFO - Saving model weights...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:07<00:00,  2.67it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 9/100, Train Loss: 0.10277196992623713\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 17:25:54,139 root - INFO - Epoch 9/100, Validation Loss: 0.10334949246687698\n","2024-05-12 17:25:54,141 root - INFO - Saving model weights...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.65it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/100, Train Loss: 0.09828780257640404\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 17:28:08,444 root - INFO - Epoch 10/100, Validation Loss: 0.11226142676283206\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.64it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 11/100, Train Loss: 0.09440113872239407\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 17:30:23,090 root - INFO - Epoch 11/100, Validation Loss: 0.09485719369146069\n","2024-05-12 17:30:23,095 root - INFO - Saving model weights...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.66it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 12/100, Train Loss: 0.08833534563675029\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 17:32:37,005 root - INFO - Epoch 12/100, Validation Loss: 0.08558442971419562\n","2024-05-12 17:32:37,007 root - INFO - Saving model weights...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.66it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 13/100, Train Loss: 0.08459591110343653\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 17:34:51,149 root - INFO - Epoch 13/100, Validation Loss: 0.08661892465384051\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.65it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 14/100, Train Loss: 0.08056481032143732\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 17:37:05,709 root - INFO - Epoch 14/100, Validation Loss: 0.08132459704744686\n","2024-05-12 17:37:05,711 root - INFO - Saving model weights...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.65it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 15/100, Train Loss: 0.07661593667479176\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 17:39:19,924 root - INFO - Epoch 15/100, Validation Loss: 0.0728769741012259\n","2024-05-12 17:39:19,926 root - INFO - Saving model weights...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:09<00:00,  2.63it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 16/100, Train Loss: 0.0713585765964996\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 17:41:35,511 root - INFO - Epoch 16/100, Validation Loss: 0.07099249728597218\n","2024-05-12 17:41:35,514 root - INFO - Saving model weights...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.66it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 17/100, Train Loss: 0.0677624975833126\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 17:43:49,639 root - INFO - Epoch 17/100, Validation Loss: 0.0668135767716556\n","2024-05-12 17:43:49,640 root - INFO - Saving model weights...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.65it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 18/100, Train Loss: 0.06397501877962997\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 17:46:04,301 root - INFO - Epoch 18/100, Validation Loss: 0.08219477135383348\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.66it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 19/100, Train Loss: 0.06339102293196056\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 17:48:18,230 root - INFO - Epoch 19/100, Validation Loss: 0.0651554493592184\n","2024-05-12 17:48:18,233 root - INFO - Saving model weights...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:09<00:00,  2.63it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 20/100, Train Loss: 0.05563810427533875\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 17:50:33,852 root - INFO - Epoch 20/100, Validation Loss: 0.06063599958980787\n","2024-05-12 17:50:33,855 root - INFO - Saving model weights...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.65it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 21/100, Train Loss: 0.05209184752380032\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 17:52:48,386 root - INFO - Epoch 21/100, Validation Loss: 0.05571534001923535\n","2024-05-12 17:52:48,388 root - INFO - Saving model weights...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.65it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 22/100, Train Loss: 0.049567941261589664\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 17:55:02,969 root - INFO - Epoch 22/100, Validation Loss: 0.06561533750183357\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.65it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 23/100, Train Loss: 0.04833324796386293\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 17:57:17,129 root - INFO - Epoch 23/100, Validation Loss: 0.05602726836668147\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.64it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 24/100, Train Loss: 0.042751071224084516\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 17:59:31,866 root - INFO - Epoch 24/100, Validation Loss: 0.05366129110048036\n","2024-05-12 17:59:31,868 root - INFO - Saving model weights...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.66it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 25/100, Train Loss: 0.040403935180497993\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 18:01:46,017 root - INFO - Epoch 25/100, Validation Loss: 0.051255984402595246\n","2024-05-12 18:01:46,020 root - INFO - Saving model weights...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.66it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 26/100, Train Loss: 0.03717445564366373\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 18:04:00,301 root - INFO - Epoch 26/100, Validation Loss: 0.04951017985837514\n","2024-05-12 18:04:00,303 root - INFO - Saving model weights...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.66it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 27/100, Train Loss: 0.03491513711352782\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 18:06:14,255 root - INFO - Epoch 27/100, Validation Loss: 0.049181003832294\n","2024-05-12 18:06:14,257 root - INFO - Saving model weights...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.66it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 28/100, Train Loss: 0.03267519675601607\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 18:08:28,535 root - INFO - Epoch 28/100, Validation Loss: 0.047750630275521705\n","2024-05-12 18:08:28,538 root - INFO - Saving model weights...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:09<00:00,  2.63it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 29/100, Train Loss: 0.030063558486591563\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 18:10:44,163 root - INFO - Epoch 29/100, Validation Loss: 0.054171679850716505\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.66it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 30/100, Train Loss: 0.02809321002825965\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 18:12:58,230 root - INFO - Epoch 30/100, Validation Loss: 0.049524489559689536\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.64it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 31/100, Train Loss: 0.026142647414528923\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 18:15:12,966 root - INFO - Epoch 31/100, Validation Loss: 0.05192383664444179\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.65it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 32/100, Train Loss: 0.02500926282508973\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 18:17:27,358 root - INFO - Epoch 32/100, Validation Loss: 0.046211751700137124\n","2024-05-12 18:17:27,361 root - INFO - Saving model weights...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.65it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 33/100, Train Loss: 0.023843943762562513\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 18:19:41,856 root - INFO - Epoch 33/100, Validation Loss: 0.05026492320773003\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.65it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 34/100, Train Loss: 0.02310588339125426\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 18:21:56,119 root - INFO - Epoch 34/100, Validation Loss: 0.04692121770263008\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.66it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 35/100, Train Loss: 0.01940952537835647\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 18:24:09,926 root - INFO - Epoch 35/100, Validation Loss: 0.045413940617308204\n","2024-05-12 18:24:09,932 root - INFO - Saving model weights...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.65it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 36/100, Train Loss: 0.018164532568756237\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 18:26:24,188 root - INFO - Epoch 36/100, Validation Loss: 0.04942832896609361\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.65it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 37/100, Train Loss: 0.01847372567760264\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 18:28:38,852 root - INFO - Epoch 37/100, Validation Loss: 0.04872690643973514\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:09<00:00,  2.63it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 38/100, Train Loss: 0.01554073481817237\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 18:30:54,242 root - INFO - Epoch 38/100, Validation Loss: 0.04763898480066822\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.65it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 39/100, Train Loss: 0.015064824955638271\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 18:33:08,823 root - INFO - Epoch 39/100, Validation Loss: 0.04893451567723764\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 341/341 [02:08<00:00,  2.65it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 40/100, Train Loss: 0.014586447902978706\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2024-05-12 18:35:23,228 root - INFO - Epoch 40/100, Validation Loss: 0.04756009100999386\n","2024-05-12 18:35:23,230 root - INFO - Early stopping triggered.\n"]}],"source":["from encoder import Encoder\n","\n","\n","config = model_config[run]\n","vit_model = Encoder(config['vit'])\n","\n","model_dir = config['vit']['model_dir']\n","\n","try:\n","    vit_model.load_weights(model_dir)\n","    logging.info(\"Model weights loaded from %s! Calculating metrics...\", model_dir)\n","except Exception as ex:\n","    logging.error(\"Error loading model weights: %s\", ex)\n","\n","vit_model.train_model(**config['vit_training'],\n","                  model_dir=config['vit']['model_dir'],\n","                  train_loader=train_loader,\n","                  val_loader=val_loader,\n","                  device=device)\n","\n","vit_model.vit.save_pretrained(config['vit']['model_dir'])"]},{"cell_type":"code","source":["vit_model.vit.save_pretrained(config['vit']['model_dir'])"],"metadata":{"id":"iUBC1FfIooIv","executionInfo":{"status":"ok","timestamp":1719054554956,"user_tz":240,"elapsed":5848,"user":{"displayName":"Xiaofeng Tan","userId":"13213533501740266205"}}},"id":"iUBC1FfIooIv","execution_count":14,"outputs":[]},{"cell_type":"markdown","id":"c19521a6-46a9-4950-a9e7-6a3adb46cad0","metadata":{"id":"c19521a6-46a9-4950-a9e7-6a3adb46cad0"},"source":["# Test the Trained Vit Model"]},{"cell_type":"code","execution_count":15,"id":"0ae138d2-c2df-4d73-b2a4-cdaef2c8f83b","metadata":{"id":"0ae138d2-c2df-4d73-b2a4-cdaef2c8f83b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719054568699,"user_tz":240,"elapsed":3000,"user":{"displayName":"Xiaofeng Tan","userId":"13213533501740266205"}},"outputId":"2458378c-9059-4fef-f265-3f160bfd0155"},"outputs":[{"output_type":"stream","name":"stdout","text":["2024-06-22 11:09:25,629 root - INFO - Device: cuda\n","2024-06-22 11:09:25,826 root - INFO - Model weights loaded from /content/drive/MyDrive/Colab Notebooks/CLAMS/models/vit_models/run8! Calculating metrics...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 43/43 [00:01<00:00, 23.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["2024-06-22 11:09:27,797 root - INFO - Accuracy: 0.909547\n","2024-06-22 11:09:27,799 root - INFO - \n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","      alkane       1.00      1.00      1.00     11846\n","      alkene       0.98      0.96      0.97      1635\n","      alkyne       0.99      0.99      0.99      1629\n","       arene       1.00      1.00      1.00        27\n","  haloalkane       0.94      0.89      0.92       217\n","     alcohol       1.00      1.00      1.00      4128\n","    aldehyde       0.99      0.99      0.99      1484\n","      ketone       0.97      0.96      0.97      1434\n","       ester       0.92      0.97      0.95       410\n","       ether       0.96      0.98      0.97      5589\n","       amine       0.95      0.92      0.94      3845\n","       amide       0.99      0.95      0.97       875\n","     nitrile       0.99      0.98      0.98      1541\n","       imide       0.98      0.88      0.92        56\n","       thial       0.99      0.99      0.99      1484\n","      phenol       0.96      0.96      0.96       322\n","     enamine       0.98      0.93      0.95       145\n","   carbamate       1.00      0.93      0.96        85\n","\n","   micro avg       0.98      0.98      0.98     36752\n","   macro avg       0.98      0.96      0.97     36752\n","weighted avg       0.98      0.98      0.98     36752\n"," samples avg       0.98      0.97      0.97     36752\n","\n"]}],"source":["from encoder import Encoder\n","from ir_smarts import SMARTS\n","\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","else:\n","    device = torch.device(\"cpu\")\n","\n","logging.info(\"Device: %s\", device)\n","\n","config = model_config[run]\n","vit_model = Encoder(config['vit'])\n","\n","vit_test_ret = vit_model.test_model(model_dir=config['vit']['model_dir'],\n","                    test_loader=test_loader, device=device,\n","                    labels=list(SMARTS.keys()))"]},{"cell_type":"code","source":["vit_test_ret['report_df'].to_hdf(\n","          os.path.join(config['vit']['model_dir'], \"vit_test_results.h5\"),\n","          key='report', mode='w')"],"metadata":{"id":"r_JKG2bZ0Wpa"},"id":"r_JKG2bZ0Wpa","execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(os.path.join(config['vit']['model_dir'], f\"vit_test_results_{run}.json\"), 'w') as fd:\n","    del vit_test_ret['report_df']\n","    json.dump(vit_test_ret, fd)"],"metadata":{"id":"YQWpujcJTXTG"},"id":"YQWpujcJTXTG","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"dbccda77-2bc7-4208-8f1c-bd1b662cdfcf","metadata":{"id":"dbccda77-2bc7-4208-8f1c-bd1b662cdfcf"},"source":["# Training the CLAMS Model"]},{"cell_type":"code","execution_count":16,"id":"ZKO_B7hYz2Zf","metadata":{"id":"ZKO_B7hYz2Zf","colab":{"base_uri":"https://localhost:8080/","height":177,"referenced_widgets":["f0e4566868734b5fa199f3fa9eef4eba","08d5ee0dd2d348bd838f1553fccaf77e","3626dc14e43e41349225a4a91c8967d7","05b9954d46c1444f81d4f5a3e6cc202d","9246d7f511094f4e99e1ecc96e240773","6c0c8950b89d4ec48c04ea7d6a07800b","5d4ad1f5364f4365830296cd3532c4bb","91f52a5c71114f11a6248f5697427ff7","e43d29ac538f482d8581752cf0103316","943ef530cec8484a9b384a10a06a745a","eb1d40060d624490ad16cc57e3086307","8a04d3837b9c4e26b8d3f0e1bd30c9fd","e1922dbee8e748d9aaeb5c7f78343a16","918bab753401444f87fd2a2ae83eca09","fb4530c42158443086ddbab8f9399e65","b1fdbb03bd3b40a2ada39ef8831d31c1","00129e8caef3470b9e2e1f790ad974b1","82380a1be5a949ab9b59ba6cda6107bd","1cf4393a03ab434aab407144f1ca71b8","19c292c9311d412bbe3a062c30473c66","25d32639a6f14db5afa5a068b9a57c9b","deef0eedb6634acfaffc10fbc332dea1","ac036f0254f14361a0f957dfc0773c5c","f8d73aa05e664a80ab59f8c8ec1f7c1c","4059af84c94f4dda96de8766ff52d579","c1d87680ccf14fa99a5c0f5b54be602c","5cec34fcee3a48189d7b5651a7a1eaa3","2777efb65d7348c5b708b939bb591f51","9c2b42b74b234f799ab3ac61fed1ab1f","fb69618995294f09830dd14665dbd43e","ccdc7761379d4f55b2a8503a07b22b1b","3a9fee9bbdb04bc4bdc61127fe08b40f","1142bf1d8a924631bdab8989f788d311","937239c871f749c69c6a99ca01253507","e372f7cc0e42420ebe4dcd6beade136e","6e20327301bb4576a69583118e57fa7a","5fe6185c76234bc5bc25ed1a87f9bab9","73a19eecf4e2472cbc8f701c880d94ce","b6ee364dfc32489cb663cb3b5155af07","1f1c0b3c7dca4989b0630213cb376092","72c1d92273164a39971c99de3d88fd73","aff5fd19b01d4a5c8a5d1b00201c94bf","dc49777647cd4aec877e8ca9f894b046","d83c8ab54faa4b50b48cdcda7e7500f5","5ca6559cebaf43ad8b60a12336d7e1c4","670431cc6bb04cebb35d8f93bfbd841b","797467dc424746fc98a8e23454d889bd","2c68e737d46944909e3e812248f9a0a3","a2d6a2c66f974f7bbf503849d162cf35","f4e4c0112c1e4f5ab452e3e60e25005a","bf40c1f43ac748ea9bb29ad9eeabe82d","ce7d4ce0eb504df9b6e77b66736ca400","69dab776790c43ac886f4dbd21a6d015","099883bd39db468381c9226c1d61c6ce","a904926768584c4f9427c90f88476836"]},"executionInfo":{"status":"ok","timestamp":1719054665174,"user_tz":240,"elapsed":33496,"user":{"displayName":"Xiaofeng Tan","userId":"13213533501740266205"}},"outputId":"bb82048a-acfb-4364-c87a-1a99fb4b33c8"},"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/62.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0e4566868734b5fa199f3fa9eef4eba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/515 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a04d3837b9c4e26b8d3f0e1bd30c9fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/165k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac036f0254f14361a0f957dfc0773c5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/101k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"937239c871f749c69c6a99ca01253507"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ca6559cebaf43ad8b60a12336d7e1c4"}},"metadata":{}}],"source":["from ir_dataset import generate_ic_dataset\n","import json\n","from transformers import AutoTokenizer\n","\n","# Pre-trained tokenizer\n","pretrained_decodert_dir = \"seyonec/PubChem10M_SMILES_BPE_450k\"\n","roberta_tokenizer = AutoTokenizer.from_pretrained(pretrained_decodert_dir)\n","\n","\n","ic_train_set = generate_ic_dataset(train_dataset, roberta_tokenizer,\n","                              max_length = config['ic_training']['max_length'])\n","ic_val_set = generate_ic_dataset(val_dataset, roberta_tokenizer,\n","                              max_length = config['ic_training']['max_length'])\n","ic_test_set = generate_ic_dataset(test_dataset, roberta_tokenizer,\n","                              max_length = config['ic_training']['max_length'])"]},{"cell_type":"code","execution_count":17,"id":"kUuZVuaaA1c0","metadata":{"id":"kUuZVuaaA1c0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719054665175,"user_tz":240,"elapsed":16,"user":{"displayName":"Xiaofeng Tan","userId":"13213533501740266205"}},"outputId":"d1c0c407-9871-42f4-ee71-1902c6273c17"},"outputs":[{"output_type":"stream","name":"stdout","text":["2024-06-22 11:11:04,701 root - INFO - Device: cuda\n"]}],"source":["if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","else:\n","    device = torch.device(\"cpu\")\n","\n","logging.info(\"Device: %s\", device)"]},{"cell_type":"code","execution_count":null,"id":"ff2738a2-ec2f-4223-b670-03bfcb855d42","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["2b1447caae084f968f72cab683ee3684","920f50cf740e4e3d8276535239631b14","9a5679b6aabf46aab8bf4f92b2a6546e","c082c978205f4e9ea30c357e139784bc","452b62aeca094c2c88da53758e7038df","1b1a74d3c8064a458e21f771f27b94eb","77c69772db3d44e69ca2f19f527ccca3","97edac5a80e84535aad22f156457dac3","49b2517278cc441d961bb8be57ec10a6","7f8f4baf31494623acd352d3f09551ed","fe2d5cdd37894332a81679cf646bb9ea"]},"id":"ff2738a2-ec2f-4223-b670-03bfcb855d42","outputId":"ff2ab110-72bc-417c-fe6a-45052d33bd2e","executionInfo":{"status":"ok","timestamp":1715473861394,"user_tz":240,"elapsed":6148530,"user":{"displayName":"Xiaofeng Tan","userId":"13213533501740266205"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["2024-05-11 22:48:32,288 root - INFO - Creating new model\n"]},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/336M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b1447caae084f968f72cab683ee3684"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForCausalLM were not initialized from the model checkpoint at seyonec/PubChem10M_SMILES_BPE_450k and are newly initialized: ['roberta.encoder.layer.0.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.0.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.output.dense.weight', 'roberta.encoder.layer.0.crossattention.self.key.bias', 'roberta.encoder.layer.0.crossattention.self.key.weight', 'roberta.encoder.layer.0.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.self.query.weight', 'roberta.encoder.layer.0.crossattention.self.value.bias', 'roberta.encoder.layer.0.crossattention.self.value.weight', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.1.crossattention.output.dense.bias', 'roberta.encoder.layer.1.crossattention.output.dense.weight', 'roberta.encoder.layer.1.crossattention.self.key.bias', 'roberta.encoder.layer.1.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.self.query.bias', 'roberta.encoder.layer.1.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.self.value.bias', 'roberta.encoder.layer.1.crossattention.self.value.weight', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.2.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.output.dense.weight', 'roberta.encoder.layer.2.crossattention.self.key.bias', 'roberta.encoder.layer.2.crossattention.self.key.weight', 'roberta.encoder.layer.2.crossattention.self.query.bias', 'roberta.encoder.layer.2.crossattention.self.query.weight', 'roberta.encoder.layer.2.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.self.value.weight', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.output.dense.bias', 'roberta.encoder.layer.3.crossattention.output.dense.weight', 'roberta.encoder.layer.3.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.self.key.weight', 'roberta.encoder.layer.3.crossattention.self.query.bias', 'roberta.encoder.layer.3.crossattention.self.query.weight', 'roberta.encoder.layer.3.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.4.crossattention.output.dense.bias', 'roberta.encoder.layer.4.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.self.key.weight', 'roberta.encoder.layer.4.crossattention.self.query.bias', 'roberta.encoder.layer.4.crossattention.self.query.weight', 'roberta.encoder.layer.4.crossattention.self.value.bias', 'roberta.encoder.layer.4.crossattention.self.value.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.output.dense.bias', 'roberta.encoder.layer.5.crossattention.output.dense.weight', 'roberta.encoder.layer.5.crossattention.self.key.bias', 'roberta.encoder.layer.5.crossattention.self.key.weight', 'roberta.encoder.layer.5.crossattention.self.query.bias', 'roberta.encoder.layer.5.crossattention.self.query.weight', 'roberta.encoder.layer.5.crossattention.self.value.bias', 'roberta.encoder.layer.5.crossattention.self.value.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='10230' max='40920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10230/40920 1:42:17 < 5:06:57, 1.67 it/s, Epoch 30/120]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.722800</td>\n","      <td>0.269946</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.262600</td>\n","      <td>0.223774</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.221700</td>\n","      <td>0.196689</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.195200</td>\n","      <td>0.175975</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.176500</td>\n","      <td>0.162704</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.161800</td>\n","      <td>0.154973</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.149500</td>\n","      <td>0.146573</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.138900</td>\n","      <td>0.138451</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.129900</td>\n","      <td>0.133828</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.121600</td>\n","      <td>0.130295</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.114200</td>\n","      <td>0.126439</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.107500</td>\n","      <td>0.122799</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.101300</td>\n","      <td>0.120126</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.095600</td>\n","      <td>0.116943</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.090400</td>\n","      <td>0.113970</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.085300</td>\n","      <td>0.113766</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.080700</td>\n","      <td>0.112443</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.076600</td>\n","      <td>0.111089</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.072300</td>\n","      <td>0.109662</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.068300</td>\n","      <td>0.109424</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.064500</td>\n","      <td>0.108731</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.061300</td>\n","      <td>0.108452</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.058000</td>\n","      <td>0.108173</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.054800</td>\n","      <td>0.109212</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.051900</td>\n","      <td>0.108029</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.049200</td>\n","      <td>0.108864</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.046700</td>\n","      <td>0.110175</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.044500</td>\n","      <td>0.109641</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.042000</td>\n","      <td>0.109839</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.040000</td>\n","      <td>0.109869</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","There were missing keys in the checkpoint model loaded: ['decoder.lm_head.decoder.weight', 'decoder.lm_head.decoder.bias'].\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n"]}],"source":["from clams import create_clams_model, train_clams_model\n","from transformers import VisionEncoderDecoderModel\n","import torch\n","\n","# If training a model from scratch, set `create_new` to True; otherwise, False\n","create_new = True\n","\n","# set encoder decoder tying to True\n","if create_new:\n","    logging.info(\"Creating new model\")\n","    model = create_clams_model(config['ic_training'], config['vit']['model_dir'],\n","                pretrained_decodert_dir, roberta_tokenizer, device=device)\n","else:\n","    logging.info(\"Loading existing model\")\n","    model = VisionEncoderDecoderModel.from_pretrained(config['ic_training']['model_dir'])\n","\n","\n","train_clams_model(model, config['ic_training'], ic_train_set, ic_val_set)\n"]},{"cell_type":"code","execution_count":null,"id":"KX5KsEOPd_Cb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1029,"status":"ok","timestamp":1715474032736,"user":{"displayName":"Xiaofeng Tan","userId":"13213533501740266205"},"user_tz":240},"id":"KX5KsEOPd_Cb","outputId":"2ffe94cf-4e15-4af0-ca99-f08053915979"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 30, 'early_stopping': True, 'num_beams': 5}\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n"]}],"source":["model.save_pretrained(\"ic_model_run8\")"]},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GslpWXrGOJ3h","executionInfo":{"status":"ok","timestamp":1719054853732,"user_tz":240,"elapsed":1308,"user":{"displayName":"Xiaofeng Tan","userId":"13213533501740266205"}},"outputId":"265a5e4e-6c7d-4ce6-99a5-054548d48972"},"id":"GslpWXrGOJ3h","execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["VisionEncoderDecoderModel(\n","  (encoder): ViTModel(\n","    (embeddings): ViTEmbeddings(\n","      (patch_embeddings): ViTPatchEmbeddings(\n","        (projection): Conv2d(1, 288, kernel_size=(6, 6), stride=(6, 6))\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): ViTEncoder(\n","      (layer): ModuleList(\n","        (0-8): 9 x ViTLayer(\n","          (attention): ViTSdpaAttention(\n","            (attention): ViTSdpaSelfAttention(\n","              (query): Linear(in_features=288, out_features=288, bias=True)\n","              (key): Linear(in_features=288, out_features=288, bias=True)\n","              (value): Linear(in_features=288, out_features=288, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=288, out_features=288, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=288, out_features=576, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=576, out_features=288, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((288,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((288,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","    (layernorm): LayerNorm((288,), eps=1e-12, elementwise_affine=True)\n","    (pooler): ViTPooler(\n","      (dense): Linear(in_features=288, out_features=288, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (decoder): RobertaForCausalLM(\n","    (roberta): RobertaModel(\n","      (embeddings): RobertaEmbeddings(\n","        (word_embeddings): Embedding(52000, 768, padding_idx=1)\n","        (position_embeddings): Embedding(512, 768, padding_idx=1)\n","        (token_type_embeddings): Embedding(1, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): RobertaEncoder(\n","        (layer): ModuleList(\n","          (0-5): 6 x RobertaLayer(\n","            (attention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): RobertaIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): RobertaOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (lm_head): RobertaLMHead(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (decoder): Linear(in_features=768, out_features=52000, bias=True)\n","    )\n","  )\n","  (enc_to_dec_proj): Linear(in_features=288, out_features=768, bias=True)\n",")"]},"metadata":{},"execution_count":24}]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[{"file_id":"1ldWfLkVG9OxJLD1Y8jU_k3v2WRhm4G0I","timestamp":1715463830680},{"file_id":"1z9-Qz5ezunz78hxvmX5WBqZd7mJtoZ0h","timestamp":1715168605835}],"gpuType":"A100"},"environment":{"kernel":"python3","name":"tf2-cpu.2-11.m118","type":"gcloud","uri":"us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m118"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2b1447caae084f968f72cab683ee3684":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_920f50cf740e4e3d8276535239631b14","IPY_MODEL_9a5679b6aabf46aab8bf4f92b2a6546e","IPY_MODEL_c082c978205f4e9ea30c357e139784bc"],"layout":"IPY_MODEL_452b62aeca094c2c88da53758e7038df"}},"920f50cf740e4e3d8276535239631b14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b1a74d3c8064a458e21f771f27b94eb","placeholder":"​","style":"IPY_MODEL_77c69772db3d44e69ca2f19f527ccca3","value":"pytorch_model.bin: 100%"}},"9a5679b6aabf46aab8bf4f92b2a6546e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_97edac5a80e84535aad22f156457dac3","max":336422980,"min":0,"orientation":"horizontal","style":"IPY_MODEL_49b2517278cc441d961bb8be57ec10a6","value":336422980}},"c082c978205f4e9ea30c357e139784bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f8f4baf31494623acd352d3f09551ed","placeholder":"​","style":"IPY_MODEL_fe2d5cdd37894332a81679cf646bb9ea","value":" 336M/336M [00:01&lt;00:00, 203MB/s]"}},"452b62aeca094c2c88da53758e7038df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b1a74d3c8064a458e21f771f27b94eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77c69772db3d44e69ca2f19f527ccca3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97edac5a80e84535aad22f156457dac3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49b2517278cc441d961bb8be57ec10a6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7f8f4baf31494623acd352d3f09551ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe2d5cdd37894332a81679cf646bb9ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f0e4566868734b5fa199f3fa9eef4eba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_08d5ee0dd2d348bd838f1553fccaf77e","IPY_MODEL_3626dc14e43e41349225a4a91c8967d7","IPY_MODEL_05b9954d46c1444f81d4f5a3e6cc202d"],"layout":"IPY_MODEL_9246d7f511094f4e99e1ecc96e240773"}},"08d5ee0dd2d348bd838f1553fccaf77e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c0c8950b89d4ec48c04ea7d6a07800b","placeholder":"​","style":"IPY_MODEL_5d4ad1f5364f4365830296cd3532c4bb","value":"tokenizer_config.json: 100%"}},"3626dc14e43e41349225a4a91c8967d7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_91f52a5c71114f11a6248f5697427ff7","max":62,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e43d29ac538f482d8581752cf0103316","value":62}},"05b9954d46c1444f81d4f5a3e6cc202d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_943ef530cec8484a9b384a10a06a745a","placeholder":"​","style":"IPY_MODEL_eb1d40060d624490ad16cc57e3086307","value":" 62.0/62.0 [00:00&lt;00:00, 4.87kB/s]"}},"9246d7f511094f4e99e1ecc96e240773":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c0c8950b89d4ec48c04ea7d6a07800b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d4ad1f5364f4365830296cd3532c4bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91f52a5c71114f11a6248f5697427ff7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e43d29ac538f482d8581752cf0103316":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"943ef530cec8484a9b384a10a06a745a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb1d40060d624490ad16cc57e3086307":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a04d3837b9c4e26b8d3f0e1bd30c9fd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e1922dbee8e748d9aaeb5c7f78343a16","IPY_MODEL_918bab753401444f87fd2a2ae83eca09","IPY_MODEL_fb4530c42158443086ddbab8f9399e65"],"layout":"IPY_MODEL_b1fdbb03bd3b40a2ada39ef8831d31c1"}},"e1922dbee8e748d9aaeb5c7f78343a16":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00129e8caef3470b9e2e1f790ad974b1","placeholder":"​","style":"IPY_MODEL_82380a1be5a949ab9b59ba6cda6107bd","value":"config.json: 100%"}},"918bab753401444f87fd2a2ae83eca09":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1cf4393a03ab434aab407144f1ca71b8","max":515,"min":0,"orientation":"horizontal","style":"IPY_MODEL_19c292c9311d412bbe3a062c30473c66","value":515}},"fb4530c42158443086ddbab8f9399e65":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25d32639a6f14db5afa5a068b9a57c9b","placeholder":"​","style":"IPY_MODEL_deef0eedb6634acfaffc10fbc332dea1","value":" 515/515 [00:00&lt;00:00, 40.1kB/s]"}},"b1fdbb03bd3b40a2ada39ef8831d31c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00129e8caef3470b9e2e1f790ad974b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82380a1be5a949ab9b59ba6cda6107bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1cf4393a03ab434aab407144f1ca71b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19c292c9311d412bbe3a062c30473c66":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"25d32639a6f14db5afa5a068b9a57c9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"deef0eedb6634acfaffc10fbc332dea1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac036f0254f14361a0f957dfc0773c5c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f8d73aa05e664a80ab59f8c8ec1f7c1c","IPY_MODEL_4059af84c94f4dda96de8766ff52d579","IPY_MODEL_c1d87680ccf14fa99a5c0f5b54be602c"],"layout":"IPY_MODEL_5cec34fcee3a48189d7b5651a7a1eaa3"}},"f8d73aa05e664a80ab59f8c8ec1f7c1c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2777efb65d7348c5b708b939bb591f51","placeholder":"​","style":"IPY_MODEL_9c2b42b74b234f799ab3ac61fed1ab1f","value":"vocab.json: 100%"}},"4059af84c94f4dda96de8766ff52d579":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb69618995294f09830dd14665dbd43e","max":164540,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ccdc7761379d4f55b2a8503a07b22b1b","value":164540}},"c1d87680ccf14fa99a5c0f5b54be602c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a9fee9bbdb04bc4bdc61127fe08b40f","placeholder":"​","style":"IPY_MODEL_1142bf1d8a924631bdab8989f788d311","value":" 165k/165k [00:00&lt;00:00, 11.1MB/s]"}},"5cec34fcee3a48189d7b5651a7a1eaa3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2777efb65d7348c5b708b939bb591f51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c2b42b74b234f799ab3ac61fed1ab1f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb69618995294f09830dd14665dbd43e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccdc7761379d4f55b2a8503a07b22b1b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3a9fee9bbdb04bc4bdc61127fe08b40f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1142bf1d8a924631bdab8989f788d311":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"937239c871f749c69c6a99ca01253507":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e372f7cc0e42420ebe4dcd6beade136e","IPY_MODEL_6e20327301bb4576a69583118e57fa7a","IPY_MODEL_5fe6185c76234bc5bc25ed1a87f9bab9"],"layout":"IPY_MODEL_73a19eecf4e2472cbc8f701c880d94ce"}},"e372f7cc0e42420ebe4dcd6beade136e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6ee364dfc32489cb663cb3b5155af07","placeholder":"​","style":"IPY_MODEL_1f1c0b3c7dca4989b0630213cb376092","value":"merges.txt: 100%"}},"6e20327301bb4576a69583118e57fa7a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_72c1d92273164a39971c99de3d88fd73","max":101307,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aff5fd19b01d4a5c8a5d1b00201c94bf","value":101307}},"5fe6185c76234bc5bc25ed1a87f9bab9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc49777647cd4aec877e8ca9f894b046","placeholder":"​","style":"IPY_MODEL_d83c8ab54faa4b50b48cdcda7e7500f5","value":" 101k/101k [00:00&lt;00:00, 8.08MB/s]"}},"73a19eecf4e2472cbc8f701c880d94ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6ee364dfc32489cb663cb3b5155af07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f1c0b3c7dca4989b0630213cb376092":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72c1d92273164a39971c99de3d88fd73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aff5fd19b01d4a5c8a5d1b00201c94bf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dc49777647cd4aec877e8ca9f894b046":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d83c8ab54faa4b50b48cdcda7e7500f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5ca6559cebaf43ad8b60a12336d7e1c4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_670431cc6bb04cebb35d8f93bfbd841b","IPY_MODEL_797467dc424746fc98a8e23454d889bd","IPY_MODEL_2c68e737d46944909e3e812248f9a0a3"],"layout":"IPY_MODEL_a2d6a2c66f974f7bbf503849d162cf35"}},"670431cc6bb04cebb35d8f93bfbd841b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4e4c0112c1e4f5ab452e3e60e25005a","placeholder":"​","style":"IPY_MODEL_bf40c1f43ac748ea9bb29ad9eeabe82d","value":"special_tokens_map.json: 100%"}},"797467dc424746fc98a8e23454d889bd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce7d4ce0eb504df9b6e77b66736ca400","max":772,"min":0,"orientation":"horizontal","style":"IPY_MODEL_69dab776790c43ac886f4dbd21a6d015","value":772}},"2c68e737d46944909e3e812248f9a0a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_099883bd39db468381c9226c1d61c6ce","placeholder":"​","style":"IPY_MODEL_a904926768584c4f9427c90f88476836","value":" 772/772 [00:00&lt;00:00, 72.1kB/s]"}},"a2d6a2c66f974f7bbf503849d162cf35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4e4c0112c1e4f5ab452e3e60e25005a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf40c1f43ac748ea9bb29ad9eeabe82d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce7d4ce0eb504df9b6e77b66736ca400":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69dab776790c43ac886f4dbd21a6d015":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"099883bd39db468381c9226c1d61c6ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a904926768584c4f9427c90f88476836":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}